{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob,os,re\n",
    "import xml.etree.ElementTree as ET\n",
    "import collections\n",
    "from unicodedata import category, normalize\n",
    "from tf.fabric import Fabric\n",
    "from tf.timestamp import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO = '~/github/pthu/pilot'\n",
    "SRC_DIR = os.path.expanduser(f'{REPO}/sources/nt')\n",
    "TF_DIR = f'{REPO}/tf'\n",
    "\n",
    "TEI = 'http://www.tei-c.org/ns/1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode tricks\n",
    "\n",
    "We show how the unicode library works, and use it to define a function that splits punctuation from words, and\n",
    "a function that converts greek accented characters to plain uppercase characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lu', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Po', 'Lu', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Zs']\n",
      "['Α', 'υ', '̓', 'τ', 'ο', 'υ', '́', 'ς', '·', 'Α', 'υ', '̓', 'τ', 'ο', 'υ', '́', 'ς', ' ']\n",
      "['Lu', 'Ll', 'Mn', 'Ll', 'Ll', 'Ll', 'Mn', 'Ll', 'Po', 'Lu', 'Ll', 'Mn', 'Ll', 'Ll', 'Ll', 'Mn', 'Ll', 'Zs']\n",
      "['Lu', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Po', 'Mn', 'Ll']\n",
      "['Σ', 'ι', 'λ', 'ω', 'α', '́', 'μ', '?', '̔', 'ο', '̔', '̀']\n",
      "['Lu', 'Ll', 'Ll', 'Ll', 'Ll', 'Mn', 'Ll', 'Po', 'Mn', 'Ll', 'Mn', 'Mn']\n"
     ]
    }
   ],
   "source": [
    "word1 = 'Αὐτούς·Αὐτούς '\n",
    "word2 = 'Σιλωάμ?̔ὃ'\n",
    "\n",
    "for word in (word1, word2):\n",
    "    print([category(x) for x in word])\n",
    "    print([x for x in normalize('NFD', word)])\n",
    "    print([category(x) for x in normalize('NFD', word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letter = {'L'}\n",
    "dia = {'M'}\n",
    "NFD = 'NFD'\n",
    "\n",
    "def splitPuncSimple(w):\n",
    "    afterWord = len(w)\n",
    "    for i in range(len(w) - 1, -1, -1):\n",
    "        if category(w[i])[0] not in letter:\n",
    "            afterWord = i\n",
    "        else:\n",
    "            break\n",
    "    return (w[0:afterWord], w[afterWord:]+' ')\n",
    "\n",
    "def splitPunc(w):\n",
    "    pP = 0\n",
    "    for i in range(len(w)):\n",
    "        if category(w[i])[0] not in letter:\n",
    "            pP += 1\n",
    "        else:\n",
    "            break\n",
    "    preWord = w[0:pP] if pP else ''\n",
    "    pW = pP\n",
    "    for i in range(pP, len(w)):\n",
    "        if category(w[i])[0] in letter:\n",
    "            pW += 1\n",
    "        else:\n",
    "            break\n",
    "    word = w[pP:pW]\n",
    "    pA = pW\n",
    "    for i in range(pW, len(w)):\n",
    "        if category(w[i])[0] not in letter:\n",
    "            pA += 1\n",
    "        else:\n",
    "            break\n",
    "    afterWord = w[pW:pA]\n",
    "    if pA == len(w):\n",
    "        afterWord += ' '\n",
    "    \n",
    "    rest = splitPunc(w[pA:]) if pA < len(w) else ()\n",
    "    return ((preWord, word, afterWord),) + rest\n",
    "\n",
    "\n",
    "def plainCaps(w):\n",
    "    return ''.join(x.upper() for x in normalize(NFD, w) if category(x)[0] not in dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('', 'Αὐτούς', '·'), ('', 'Αὐτούς', '  '))\n",
      "(('', 'Σιλωάμ', '?̔'), ('', 'ὃ', ' '))\n"
     ]
    }
   ],
   "source": [
    "for word in (word1, word2):\n",
    "    print(splitPunc(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 5.5.11\n",
      "Api reference : https://dans-labs.github.io/text-fabric/Api/General/\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "14 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "tm = Timestamp()\n",
    "TF = Fabric(locations=TF_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, bookEn):\n",
    "        self.bookEn = bookEn\n",
    "        self.tfFromXml = {}\n",
    "        self.xmlFromTf = {}\n",
    "        self.nodeNum = 1\n",
    "        self.maxSlot = 0\n",
    "        self.maxNode = 0\n",
    "        self.paths = {}\n",
    "        self.nodeFeatures = collections.defaultdict(dict)\n",
    "        self.edgeFeatures = collections.defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = None\n",
    "chapter = None\n",
    "verse = None\n",
    "\n",
    "def walkNode(node):\n",
    "    global book\n",
    "    global chapter\n",
    "    global verse\n",
    "    \n",
    "    n = data.nodeNum\n",
    "    if node.tag == f'{{{TEI}}}div':\n",
    "        xType = node.attrib['type']\n",
    "        if xType == 'edition':\n",
    "            book = n\n",
    "            data.nodeFeatures['otype'][n] = 'book'\n",
    "            data.nodeFeatures['book'][n] = data.bookEn\n",
    "            data.nodeNum += 1\n",
    "        else:\n",
    "            xSubType = node.attrib['subtype']\n",
    "            if xSubType == 'chapter':\n",
    "                chapter = n\n",
    "                data.nodeFeatures['otype'][n] = 'chapter'\n",
    "                data.nodeFeatures['chapter'][n] = int(node.attrib['n'])\n",
    "                data.nodeNum += 1\n",
    "            elif xSubType == 'verse':\n",
    "                verse = n\n",
    "                data.nodeFeatures['otype'][n] = 'verse'\n",
    "                data.nodeFeatures['verse'][n] = int(node.attrib['n'])\n",
    "                data.nodeNum += 1\n",
    "                if len(node) == 0:\n",
    "                    n = data.nodeNum\n",
    "                    data.nodeFeatures['otype'][n] = 'word'\n",
    "                    data.nodeFeatures['orig'][n] = ''\n",
    "                    data.nodeFeatures['main'][n] = ''\n",
    "                    data.nodeFeatures['plain'][n] = ''\n",
    "                    for parent in (book, chapter, verse):\n",
    "                        data.edgeFeatures['oslots'].setdefault(parent, []).append(n)\n",
    "                    data.nodeNum += 1\n",
    "    if node.tag == f'{{{TEI}}}p':\n",
    "        for elem in node.iter():\n",
    "            if elem.tag == f'{{{TEI}}}milestone':\n",
    "                unit = elem.attrib['unit']\n",
    "                unitAssigned = False\n",
    "            else:\n",
    "                unit = None\n",
    "            if elem.tag == f'{{{TEI}}}pb':\n",
    "                page = elem.attrib['n']\n",
    "                pageAssigned = False\n",
    "            else:\n",
    "                page = None\n",
    "            for wordStr in (elem.text, elem.tail):\n",
    "                if wordStr:\n",
    "                    for word in wordStr.split():\n",
    "                        for (preWord, midWord, postWord) in splitPunc(word):\n",
    "                            n = data.nodeNum\n",
    "                            if unit and not unitAssigned:\n",
    "                                data.nodeFeatures[unit][n] = '+'\n",
    "                                unitAssigned = True\n",
    "                            if page and not pageAssigned:\n",
    "                                data.nodeFeatures['page'][n] = page\n",
    "                                pageAssigned = True\n",
    "                            data.nodeFeatures['otype'][n] = 'word'\n",
    "                            wordPlain = plainCaps(midWord)\n",
    "                            data.nodeFeatures['orig'][n] = word\n",
    "                            data.nodeFeatures['main'][n] = midWord\n",
    "                            data.nodeFeatures['plain'][n] = plainCaps(midWord)\n",
    "                            if preWord != '':\n",
    "                                data.nodeFeatures['pre'][n] = preWord\n",
    "                            if postWord != '':\n",
    "                                data.nodeFeatures['post'][n] = postWord\n",
    "                            for parent in (book, chapter, verse):\n",
    "                                data.edgeFeatures['oslots'].setdefault(parent, []).append(n)\n",
    "                            data.nodeNum += 1\n",
    "    for child in node:\n",
    "        walkNode(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNode(root):\n",
    "    global data\n",
    "    \n",
    "    found = False\n",
    "    for tsElem in root.iter(f'{{{TEI}}}titleStmt'):\n",
    "        if found:\n",
    "            break\n",
    "        for tElem in tsElem.findall(f'{{{TEI}}}title'):\n",
    "            title = tElem.text\n",
    "            comps = title.split(' - ', maxsplit=1)\n",
    "            if len(comps) == 2 and comps[0].lower() == 'new testament':\n",
    "                bookEn = comps[1].strip()\n",
    "                found = True\n",
    "                break\n",
    "    if not found:\n",
    "        tm.error('No book name found')\n",
    "        return \n",
    "    tm.info(f'Book = {bookEn}')\n",
    "    data = Data(bookEn)\n",
    "        \n",
    "    for txElem in root.iter(f'{{{TEI}}}body'):\n",
    "        walkNode(txElem)\n",
    "    data.maxNode = data.nodeNum - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSections():\n",
    "    noSlots = []\n",
    "    for n in range(1, data.maxNode + 1):\n",
    "        nType = data.nodeFeatures['otype'][n]\n",
    "        if nType != 'word':\n",
    "            if n not in data.edgeFeatures['oslots']:\n",
    "                noSlots.append(n)\n",
    "    print(f'{len(noSlots)} nodes without slots')\n",
    "    for n in noSlots[0:10]:\n",
    "        nType = data.nodeFeatures['otype'][n]\n",
    "        print(f'{nType} {n} has no slots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder():\n",
    "    otypeValues = set(data.nodeFeatures['otype'].values())\n",
    "    otypeRank = dict(((val, ' ' if val == 'word' else val) for val in otypeValues))\n",
    "    newIds = sorted(range(1, data.maxNode + 1), key=lambda n: (otypeRank[data.nodeFeatures['otype'][n]], n))\n",
    "    mapping = dict(((v, i+1) for (i, v) in enumerate(newIds)))\n",
    "    \n",
    "    orderedFeatures = {}\n",
    "    for (name, dat) in data.nodeFeatures.items():\n",
    "        orderedFeatures[name] = dict(((mapping[n], v) for (n, v) in dat.items()))\n",
    "    data.nodeFeatures = orderedFeatures\n",
    "\n",
    "    orderedFeatures = {}\n",
    "    for (name, dat) in data.edgeFeatures.items():\n",
    "        orderedFeatures[name] = dict(((mapping[n], [mapping[m] for m in v]) for (n, v) in dat.items()))\n",
    "    data.edgeFeatures = orderedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Scanning XML sources of NT books found\n",
      "   |     0.00s parsing tlg0031.tlg004.opp-grc1\n",
      "   |     0.02s Book = John\n",
      "  0.30s Processing data ...\n",
      "0 nodes without slots\n",
      "  0.35s Done: collected 16496 nodes\n"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "\n",
    "tm.indent(reset=True)\n",
    "tm.info('Scanning XML sources of NT books found')\n",
    "for xmlfile in glob.glob(SRC_DIR+'/*.xml'):\n",
    "    tm.indent(level=1, reset=True)\n",
    "    (dirName, baseName) = os.path.split(xmlfile)\n",
    "    (fileName, extension) = os.path.splitext(baseName)\n",
    "    tm.info(f'parsing {fileName}')\n",
    "    tree = ET.parse(xmlfile)\n",
    "    root = tree.getroot()\n",
    "    getNode(root)\n",
    "tm.indent(level=0)\n",
    "tm.info('Processing data ...')\n",
    "reorder()\n",
    "checkSections()\n",
    "data.nodeFeatures['book@en'] = data.nodeFeatures['book']\n",
    "tm.info(f'Done: collected {data.maxNode} nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numberFeatures = {'chapter', 'verse'}\n",
    "\n",
    "metaData = {\n",
    "    '': dict(\n",
    "        createdBy='Ernst Boogert and Dirk Roorda',\n",
    "    ),\n",
    "    'otext': {\n",
    "        'sectionFeatures': 'book,chapter,verse',\n",
    "        'sectionTypes': 'book,chapter,verse',\n",
    "        'fmt:text-orig-full': '{orig} ',\n",
    "        'fmt:text-orig-main': '{main} ',\n",
    "        'fmt:text-orig-plain': '{plain} ',\n",
    "    },\n",
    "    'book@en': {\n",
    "        'valueType': 'str',\n",
    "        'language': 'English',\n",
    "        'languageCode': 'en',\n",
    "        'languageEnglish': 'english',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book',\n",
       " 'book@en',\n",
       " 'chapter',\n",
       " 'main',\n",
       " 'orig',\n",
       " 'otype',\n",
       " 'page',\n",
       " 'para',\n",
       " 'plain',\n",
       " 'post',\n",
       " 'pre',\n",
       " 'verse']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(data.nodeFeatures.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Exporting 12 node and 1 edge and 1 config features to /Users/dirk/github/pthu/pilot/tf:\n",
      "   |     0.01s T book                 to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.00s T book@en              to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.00s T chapter              to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.05s T main                 to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.04s T orig                 to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.01s T otype                to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.00s T page                 to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.00s T para                 to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.04s T plain                to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.03s T post                 to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.00s T pre                  to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.00s T verse                to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.01s T oslots               to /Users/dirk/github/pthu/pilot/tf\n",
      "   |     0.00s M otext                to /Users/dirk/github/pthu/pilot/tf\n",
      "  0.23s Exported 12 node features and 1 edge features and 1 config features to /Users/dirk/github/pthu/pilot/tf\n"
     ]
    }
   ],
   "source": [
    "for nf in data.nodeFeatures:\n",
    "    metaData.setdefault(nf, {})['valueType'] = 'int' if nf in numberFeatures else 'str'\n",
    "for ef in data.edgeFeatures:\n",
    "    metaData.setdefault(ef, {})['valueType'] = 'int' if ef in numberFeatures else 'str'\n",
    "\n",
    "TF.save(nodeFeatures=data.nodeFeatures, edgeFeatures=data.edgeFeatures, metaData=metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
